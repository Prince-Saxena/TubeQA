# TubeQA - YouTube Video Assistant ðŸŽ¥ðŸ¤–

![TubeQA Screenshot](/images/image.png)

---

## ðŸŽ¯ Purpose

As a Data Scientist, I built TubeQA to explore the integration of:

- Natural Language Processing (NLP)  
- Retrieval-Augmented Generation (RAG)  
- YouTube data mining  
- FastAPI for real-time ML serving  
- LangChain for chaining LLM-based pipelines  

This project enables interactive question answering over YouTube videos â€” a practical use case of RAG for extracting insights from unstructured video transcripts.

---

## âœ¨ Key Features

- ðŸŽ¯ Ask questions about any YouTube video  
- ðŸ§  AI-powered answers using LangChain  
- ðŸ“ Summarize long video content  
- ðŸŒ“ Dark/Light mode toggle  
- ðŸ•’ Timestamped conversation history  
- âš¡ FastAPI backend with real-time response  

---

## ðŸ”§ Tech Stack

### ðŸ“¦ Backend
- Python 3.12  
- FastAPI â€“ high-performance backend  
- LangChain â€“ for Retrieval-Augmented Generation (RAG)  
- YouTube Transcript API â€“ fetch captions  
- Google Gemini (Generative AI) â€“ question answering  
- HuggingFace Sentence Transformers â€“ embedding text  
- FAISS â€“ vector similarity search  

### ðŸ’» Frontend
- HTML5 + Tailwind CSS â€“ responsive UI  
- JavaScript (Vanilla) â€“ interactivity  
- YouTube IFrame API â€“ video embedding  

---

## ðŸ§  LangChain RAG Architecture

> âœ… Enable Mermaid rendering in GitHub or use any compatible markdown viewer.

```mermaid
graph TD
    A[User Input via UI] --> B[Extract YouTube Video ID]
    B --> C[Fetch Transcript from YouTube]
    C --> D[Chunk Transcript]
    D --> E[Generate Embeddings (HuggingFace)]
    E --> F[Store in FAISS Vector DB]
    A2[User Query] --> H[Convert to Embedding]
    H --> I[Semantic Search in FAISS]
    I --> J[Retrieve Top-k Chunks]
    J --> K[LangChain + Gemini API]
    K --> L[Answer Generation]
    L --> M[Return Answer to UI]
